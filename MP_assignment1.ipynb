{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7047c9",
   "metadata": {},
   "source": [
    "# Homework Assignment: Building and Comparing High-Performance FashionMNIST Models\n",
    "\n",
    "**Objective:**\n",
    "Based on the attached notebook, further develop models for the FashionMNIST dataset that are highly accurate, lightweight, and optimized for fast inference. In this assignment you will experiment with:\n",
    "\n",
    "- One custom CNN model.\n",
    "- Five pretrained models (with some layers frozen).\n",
    "- Five different sampling strategies.\n",
    "- Various optimizers and learning schedulers.\n",
    "- Different random seeds.\n",
    "- Experimentation with loss functions on the best validation model.\n",
    "- Model inference optimization using `torch.compile` (PyTorch 2.0+).\n",
    "\n",
    "Your final deliverable should compare performance (accuracy, inference speed, model size) across these settings and include explanations for your design choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865c893",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation and Visualization\n",
    "\n",
    "**Question 1:**\n",
    "Examine the attached code for the FashionMNIST data loader.\n",
    "\n",
    "- **Task:** Explain how the `FashionMNISTSubset` class gathers images and labels, and why a base transform is applied before splitting the data, with heavier augmentation later applied to the training set.\n",
    "\n",
    "_(Write your explanation in a markdown cell below.)_\n",
    "\n",
    "\n",
    "How the FashionMNISTSubset class gathers images and labels\n",
    "\n",
    "The FashionMNISTSubset class uses subfolder names as labels. It first iterates through these subfolders to collect label names. Then, it iterates inside each folder to gather the paths of the images. Finally, it generates a list of image paths and their corresponding labels.\n",
    "\n",
    "Why a base transform is applied before splitting, with heavier augmentation later applied to the training set\n",
    "\n",
    "The base transform normalizes the data, not only shifting it to the range [-1,1] but also scaling (stretching or compressing) the distribution to make it more balanced and well-behaved. This ensures stable learning and inference.\n",
    "After splitting, heavier augmentations (flipping, rotation, and normalization) are applied only to the training set to improve generalization by providing more diverse samples. \n",
    "The test set remains unaltered to reflect real-world evaluation conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94931b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /work/flemingc/JonReath/Trac/fashion_mnist_subset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c738e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Train Batch: torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base Data Loader Code\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class FashionMNISTSubset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths, self.labels = [], []\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(sorted(os.listdir(root_dir)))}\n",
    "        for class_name, idx in self.class_to_idx.items():\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    self.labels.append(idx)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "# Define transforms\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def split_dataset(dataset, train_ratio=0.8):\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return random_split(dataset, [train_size, test_size])\n",
    "\n",
    "def get_dataloaders(root_dir, batch_size=32):\n",
    "    dataset = FashionMNISTSubset(root_dir, transform=base_transform)\n",
    "    train_set, test_set = split_dataset(dataset)\n",
    "    # Override training set transform with augmentation\n",
    "    train_set.dataset.transform = train_transform\n",
    "    # Using a WeightedRandomSampler for class imbalance\n",
    "    class_counts = torch.bincount(torch.tensor([dataset.labels[i] for i in train_set.indices]))\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    sample_weights = [class_weights[dataset.labels[i]] for i in train_set.indices]\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, sampler=sampler)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    dataset_sizes={'train':train_set.__sizeof__(), 'val':test_set.__sizeof__()}\n",
    "    return train_loader, test_loader,dataset_sizes\n",
    "\n",
    "# Load dataloaders\n",
    "root_dir = \"fashion_mnist_subset\"  # Adjust if needed\n",
    "train_loader, test_loader,dataset_sizes = get_dataloaders(root_dir)\n",
    "\n",
    "def visualize_samples(dataloader, class_names, num_samples=6):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(12, 6))\n",
    "    for i in range(num_samples):\n",
    "        img = images[i].squeeze().numpy()\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(class_names[labels[i].item()])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "class_names = sorted(os.listdir(root_dir))\n",
    "\n",
    "# Visualize a training batch\n",
    "for images, labels in train_loader:\n",
    "    print(\"Train Batch:\", images.shape, labels.shape)\n",
    "    visualize_samples(train_loader, class_names)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156de13d",
   "metadata": {},
   "source": [
    "## Part 2: Model Development – Custom and Pretrained Models\n",
    "\n",
    "**Question 2a: Custom Model**\n",
    "\n",
    "- **Task:** Design and implement a custom CNN model that is compact, fast, and accurate for FashionMNIST. Include your training loop and evaluation code.\n",
    "\n",
    "_(Discuss your design choices in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81df39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Custom CNN Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(32)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.fc1   = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2   = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the custom model\n",
    "custom_model = CustomCNN(num_classes=10).to(device)\n",
    "print(custom_model)\n",
    "\n",
    "# TODO: Add your training and evaluation code for the custom model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a92fe",
   "metadata": {},
   "source": [
    "This code is modified from torch tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e481856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "\n",
    "def train(model,criterion,optimizer,scheduler,num_epochs=100):\n",
    "    since =time.time()\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir,'best_model_params.pt')\n",
    "        torch.save(model.state_dict(),best_model_params_path)\n",
    "        best_acc=0\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch{epoch}{num_epochs-1}')\n",
    "            print('_'*10)\n",
    "            for phase in [\"train\",\"val\"]:\n",
    "                if phase==\"train\":\n",
    "                    model.train()\n",
    "                if phase==\"val\":\n",
    "                    model.val()\n",
    "                running_loss=0\n",
    "                running_corrects=0\n",
    "                for inputs,labels in train_loader[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase=\"train\"):\n",
    "                        _,preds = torch.max(outputs,1)\n",
    "                        loss=criterion(outputs,labels)\n",
    "                        if phase=='train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_loss+=loss.item()*inputs.size(0)\n",
    "                    running_corrects+=torch.sum(preds==labels.data)\n",
    "                if phase=='train':\n",
    "                    scheduler.step()\n",
    "                \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(),best_model_params_path)\n",
    "            print()\n",
    "        time_elapsed = time.time() -since\n",
    "        print(f'Trainning complete in {time_elapsed // 60:.0f}m{time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc:{best_acc:4f}')\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93115fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = custom_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6c64e",
   "metadata": {},
   "source": [
    "**Question 2b: Pretrained Models**\n",
    "\n",
    "- **Task:** Adapt and fine-tune five pretrained models (e.g., ResNet18, MobileNet_V2, EfficientNet, VGG16, DenseNet121). Freeze some early layers and replace the final classifier to output 10 classes.\n",
    "\n",
    "_(Explain your modifications and training strategy in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70455f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[1;32m      2\u001b[0m                        num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "model_ft = train(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Example with ResNet18\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "for name, param in pretrained_model.named_parameters():\n",
    "    if \"layer1\" in name or \"layer2\" in name or \"layer3\" in name:\n",
    "        param.requires_grad = False\n",
    "num_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_features, 10)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "print(pretrained_model)\n",
    "\n",
    "# TODO: Add your training and evaluation code for the pretrained model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9b059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "135aa9ef",
   "metadata": {},
   "source": [
    "**Question 2c: Loss Functions Experiment**\n",
    "\n",
    "- **Task:** For the best validation model from Part 2b, experiment with at least two different loss functions (e.g., CrossEntropyLoss vs. a custom loss or Label Smoothing loss). Report how each loss function impacts convergence and final accuracy.\n",
    "\n",
    "_(Explain your findings in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41f3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Loss: 1.5142567157745361\n",
      "Custom Loss: 1.5142567157745361\n"
     ]
    }
   ],
   "source": [
    "# Example: Loss Functions Experiment\n",
    "criterion_standard = nn.CrossEntropyLoss()\n",
    "\n",
    "# Custom loss function example (modify as needed)\n",
    "def custom_loss(output, target):\n",
    "    loss = nn.CrossEntropyLoss()(output, target)\n",
    "    return loss * 1.0  # Adjust scaling if necessary\n",
    "\n",
    "# Assume 'best_pretrained_model' is the best model from Part 2b\n",
    "# Replace dummy_input and dummy_target with your actual batch data\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Adjust dimensions for pretrained model\n",
    "dummy_target = torch.tensor([0]).to(device)\n",
    "\n",
    "outputs = pretrained_model(dummy_input)\n",
    "loss_standard = criterion_standard(outputs, dummy_target)\n",
    "loss_custom = custom_loss(outputs, dummy_target)\n",
    "\n",
    "print(\"Standard Loss:\", loss_standard.item())\n",
    "print(\"Custom Loss:\", loss_custom.item())\n",
    "\n",
    "# TODO: Record your observations and compare convergence behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ddbf1",
   "metadata": {},
   "source": [
    "## Part 3: Experimenting with Sampling Strategies, Optimizers, and Learning Schedulers\n",
    "\n",
    "**Question 3a: Sampling Strategies**\n",
    "\n",
    "- **Task:** Implement and compare at least five different sampling strategies in your DataLoader.\n",
    "\n",
    "_(Describe in a markdown cell the scenarios in which each strategy might be preferred.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler, RandomSampler, SubsetRandomSampler, BatchSampler\n",
    "\n",
    "# Example using SequentialSampler\n",
    "sequential_sampler = SequentialSampler(train_loader.dataset)\n",
    "sequential_loader = DataLoader(train_loader.dataset, batch_size=16, sampler=sequential_sampler)\n",
    "\n",
    "# TODO: Experiment with other samplers and compare performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c371a",
   "metadata": {},
   "source": [
    "**Question 3b: Optimizers and Learning Schedulers**\n",
    "\n",
    "- **Task:** Experiment with at least two optimizers (e.g., Adam, SGD with momentum) and two learning schedulers (e.g., StepLR, CosineAnnealingLR). Compare their effects on convergence and final accuracy.\n",
    "\n",
    "_(Include training curves and discussion in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80161268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for the custom model:\n",
    "optimizer_custom = optim.Adam(custom_model.parameters(), lr=0.001)\n",
    "scheduler_custom = optim.lr_scheduler.StepLR(optimizer_custom, step_size=5, gamma=0.1)\n",
    "\n",
    "# TODO: Insert your training loop and plot loss/accuracy curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af62b65",
   "metadata": {},
   "source": [
    "**Question 3c: Random Seed Sensitivity**\n",
    "\n",
    "- **Task:** Train at least one model using three different random seeds and report the impact on training stability and accuracy.\n",
    "\n",
    "_(Explain your observations in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in [42, 123, 2021]:\n",
    "    torch.manual_seed(seed)\n",
    "    print(f\"Training with random seed: {seed}\")\n",
    "    # TODO: Reinitialize your model, optimizer, DataLoader as needed, and run your training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658a903",
   "metadata": {},
   "source": [
    "## Part 4: Inference Optimization with Model Compilation\n",
    "\n",
    "**Question 4:**\n",
    "\n",
    "- **Task:** Use PyTorch 2.0’s `torch.compile` to optimize your model's inference speed. Compare inference times before and after compilation using a dummy input.\n",
    "\n",
    "_(Discuss the speedup and any limitations in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29714af",
   "metadata": {},
   "source": [
    "## Part 5: Final Analysis and Reflection\n",
    "\n",
    "**Question 5:**\n",
    "\n",
    "- **Task:** Compare the performance of all models and configurations (custom vs. pretrained, sampling strategies, optimizer/scheduler combinations, random seeds, loss functions, and inference optimization). Create a summary table of key metrics (accuracy, model size, inference time).\n",
    "\n",
    "_(Write a detailed discussion of the trade-offs observed in a markdown cell.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample results table (update with your experimental data)\n",
    "results = {\n",
    "    \"Model\": [\"Custom\", \"ResNet18\", \"MobileNet_V2\", \"EfficientNet\", \"VGG16\", \"DenseNet121\"],\n",
    "    \"Accuracy (%)\": [92.5, 93.0, 92.8, 93.5, 91.7, 92.0],\n",
    "    \"Params (M)\": [0.5, 11.7, 3.5, 5.3, 138, 8.0],\n",
    "    \"Inference Time (ms)\": [5.2, 12.0, 7.5, 9.0, 15.0, 8.5]\n",
    "}\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de37434",
   "metadata": {},
   "source": [
    "## Final Reflection\n",
    "\n",
    "**Question 6:**\n",
    "\n",
    "- **Task:** Write a concluding summary discussing the trade-offs between model accuracy, size, and inference speed; how different sampling strategies, optimizers/schedulers, loss functions, and random seeds affected training; and which configurations would be most suitable for production.\n",
    "\n",
    "_(Provide your final reflection in a markdown cell.)_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
